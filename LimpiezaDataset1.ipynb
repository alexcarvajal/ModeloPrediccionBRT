{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1o3ydtCGKzbC433T8nuSEeQzmXOHS6t14",
      "authorship_tag": "ABX9TyM9OcZhVTgUaiH37QLkRhtz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexcarvajal/ModeloPrediccionBRT/blob/main/LimpiezaDataset1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3N1GX61LbN0c",
        "outputId": "049d8ee9-18b9-4020-ced5-b10a778d73af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 23553 entries, 8671 to 106185\n",
            "Data columns (total 11 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   Month            23553 non-null  int64  \n",
            " 1   Day              23553 non-null  int64  \n",
            " 2   Day_Week_Number  23553 non-null  int64  \n",
            " 3   Holidays         23553 non-null  float64\n",
            " 4   Hour             23553 non-null  int64  \n",
            " 5   Minute           23553 non-null  int64  \n",
            " 6   Station          23553 non-null  object \n",
            " 7   Station_Access   23553 non-null  object \n",
            " 8   Device           23553 non-null  int64  \n",
            " 9   Inputs           23553 non-null  int64  \n",
            " 10  Outputs          23553 non-null  int64  \n",
            "dtypes: float64(1), int64(8), object(2)\n",
            "memory usage: 2.2+ MB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 18362 entries, 8700 to 106172\n",
            "Data columns (total 11 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   Month            18362 non-null  int64  \n",
            " 1   Day              18362 non-null  int64  \n",
            " 2   Day_Week_Number  18362 non-null  int64  \n",
            " 3   Holidays         18362 non-null  float64\n",
            " 4   Hour             18362 non-null  int64  \n",
            " 5   Minute           18362 non-null  int64  \n",
            " 6   Station          18362 non-null  object \n",
            " 7   Station_Access   18362 non-null  object \n",
            " 8   Device           18362 non-null  int64  \n",
            " 9   Inputs           18362 non-null  int64  \n",
            " 10  Outputs          18362 non-null  int64  \n",
            "dtypes: float64(1), int64(8), object(2)\n",
            "memory usage: 1.7+ MB\n",
            "['(09000)Cabecera Usme' '(07000)Portal Sur' '(08000)Portal Tunal'\n",
            " '(10000)Portal 20 de Julio' '(06000)Portal Eldorado'\n",
            " '(05000)Portal Américas' '(03000)Portal Suba'\n",
            " '(02000)Cabecera Autopista Norte' '(04000)Cabecera Calle 80'\n",
            " '(02300)Calle 100']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import holidays\n",
        "\n",
        "url1 = '/content/drive/MyDrive/Trabajo de Grado/salidas20230809Eng.csv'\n",
        "data1 = pd.read_csv(url1)\n",
        "data1\n",
        "\n",
        "# Dropping the 'Operador' and 'Linea' columns\n",
        "data1_dropped = data1.drop(columns=['Operator', 'Line', 'archive'])\n",
        "filtered_data0 = data1_dropped[(data1_dropped['Inputs'] == 0) & (data1_dropped['Outputs'] == 0)]\n",
        "filtered_data0\n",
        "filtered_data = data1_dropped[(data1_dropped['Inputs'] != 0) | (data1_dropped['Outputs'] != 0)]\n",
        "filtered_data\n",
        "\n",
        "#Filtrar las filas que tienen un valor en la columna 'Tiempo' mayor a '03:45:00'\n",
        "filtered_time_data = filtered_data[filtered_data['Time'] >= '03:45:00']\n",
        "# Mostrar las primeras filas del DataFrame filtrado por tiempo\n",
        "unique = len(filtered_time_data['Station'].unique())\n",
        "\n",
        "#filtered_time_data.to_csv('salidas20230809EngOPLiArc0FilasTiempo345.csv')\n",
        "\n",
        "# Agrupar por la columna 'Estacion' y sumar los valores de 'Entradas_E'\n",
        "top_estaciones = filtered_time_data.groupby('Station')['Inputs'].sum()\n",
        "\n",
        "estaciones_seleccionadas = ['(02000)Cabecera Autopista Norte', '(02300)Calle 100','(03000)Portal Suba', '(04000)Cabecera Calle 80','(05000)Portal Américas', '(06000)Portal Eldorado','(07000)Portal Sur','(08000)Portal Tunal','(09000)Cabecera Usme','(10000)Portal 20 de Julio']\n",
        "#top_10_estaciones = top_estaciones.sort_values(ascending=False).head(10)\n",
        "#top_10_estaciones\n",
        "\n",
        "# Filtrar el dataset para incluir solo las 10 estaciones con la mayor cantidad de entradas\n",
        "filtered_top_10_estaciones_data =filtered_time_data[filtered_time_data['Station'].isin(estaciones_seleccionadas)].copy()\n",
        "filtered_top_10_estaciones_data\n",
        "\n",
        "\n",
        "# Mostrar las primeras filas del nuevo DataFrame filtrado\n",
        "#filtered_top_10_estaciones_data.to_csv('salidas20230809EngOPLiArc0FilasTiempo34510estaciones.csv')\n",
        "filtered_top_10_estaciones_data\n",
        "# Convirtiendo la columna 'Fecha_Transaccion' a tipo de dato de fecha\n",
        "filtered_top_10_estaciones_data['Transaction_date'] = pd.to_datetime(filtered_top_10_estaciones_data['Transaction_date'])\n",
        "# Crear la columna 'Dia_Semana'\n",
        "filtered_top_10_estaciones_data['Day_Week_Number'] = filtered_top_10_estaciones_data['Transaction_date'].dt.dayofweek + 1\n",
        "\n",
        "# Dias festivos\n",
        "\n",
        "co_holidays = holidays.Colombia(years=[2023])\n",
        "filtered_top_10_estaciones_data['Holidays'] = filtered_top_10_estaciones_data['Transaction_date'].apply(lambda x: x in co_holidays)\n",
        "\n",
        "filtered_top_10_estaciones_data['Holidays'] = filtered_top_10_estaciones_data['Holidays'].astype(float)\n",
        "\n",
        "filtered_top_10_estaciones_data['Transaction_date'] = pd.to_datetime(filtered_top_10_estaciones_data['Transaction_date'])\n",
        "\n",
        "\n",
        "# Creando las nuevas columnas para año, mes y día\n",
        "filtered_top_10_estaciones_data['Year'] = filtered_top_10_estaciones_data['Transaction_date'].dt.year\n",
        "filtered_top_10_estaciones_data['Month'] = filtered_top_10_estaciones_data['Transaction_date'].dt.month\n",
        "filtered_top_10_estaciones_data['Day'] = filtered_top_10_estaciones_data['Transaction_date'].dt.day\n",
        "\n",
        "# Eliminando la columna original 'Fecha_Transaccion'\n",
        "filtered_top_10_estaciones_data.drop('Transaction_date', axis=1,inplace=True)\n",
        "filtered_top_10_estaciones_data\n",
        "\n",
        "# Asegurándose de que 'Tiempo' sea un tipo de dato de hora\n",
        "filtered_top_10_estaciones_data['Time'] = pd.to_datetime(filtered_top_10_estaciones_data['Time'], format='%H:%M:%S').dt.time\n",
        "\n",
        "# Creando nuevas columnas para hora, minuto y segundo\n",
        "filtered_top_10_estaciones_data['Hour'] = filtered_top_10_estaciones_data['Time'].apply(lambda x: x.hour)\n",
        "filtered_top_10_estaciones_data['Minute'] = filtered_top_10_estaciones_data['Time'].apply(lambda x: x.minute)\n",
        "filtered_top_10_estaciones_data['Second'] = filtered_top_10_estaciones_data['Time'].apply(lambda x: x.second)\n",
        "\n",
        "# Eliminando la columna original 'Tiempo'\n",
        "filtered_top_10_estaciones_data.drop(['Time','Second','Year'], axis=1,inplace=True)\n",
        "# Mostrar las primeras filas del DataFrame modificado\n",
        "filtered_top_10_estaciones_data\n",
        "\n",
        "#ordered_columns = ['Month', 'Day', 'Hour', 'Minute', 'Station',\n",
        " #                  'Station_Access', 'Device', 'Inputs', 'Outputs']\n",
        "ordered_columns = ['Month', 'Day', 'Day_Week_Number', 'Holidays', 'Hour', 'Minute', 'Station', 'Station_Access', 'Device', 'Inputs', 'Outputs']\n",
        "data_reorganized = filtered_top_10_estaciones_data[ordered_columns].copy()\n",
        "\n",
        "#data_reorganized.to_csv('construccion.csv')\n",
        "data_reorganized['Inputs'].sum()\n",
        "# Supongamos que quieres eliminar filas donde la columna 'ColumnaConCeros' tiene valores 0\n",
        "data1_filtrado = data_reorganized.loc[data_reorganized['Inputs'] != 0]\n",
        "data_reorganized.info()\n",
        "data1_filtrado.info()\n",
        "data_reorganized\n",
        "\n",
        "unicos= data_reorganized['Station'].unique()\n",
        "print(unicos)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M_O-YxWqcCVE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}