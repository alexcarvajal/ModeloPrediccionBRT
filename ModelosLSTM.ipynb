{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ZfEogyN-K4hPhhNCVhK3Ww2r1iAsmEg7",
      "authorship_tag": "ABX9TyPvcqRTWE7JgsVPWQ13xjX3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexcarvajal/ModeloPrediccionBRT/blob/main/ModelosLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo LSTM 70-30"
      ],
      "metadata": {
        "id": "g0r-OOy2QMIR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzOlyrRgJ4v_",
        "outputId": "330617f7-c697-48f4-9597-bf592cb3a2a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "9569/9569 - 38s - loss: 0.0090 - 38s/epoch - 4ms/step\n",
            "Epoch 2/10\n",
            "9569/9569 - 34s - loss: 0.0072 - 34s/epoch - 4ms/step\n",
            "Epoch 3/10\n",
            "9569/9569 - 35s - loss: 0.0064 - 35s/epoch - 4ms/step\n",
            "Epoch 4/10\n",
            "9569/9569 - 33s - loss: 0.0062 - 33s/epoch - 3ms/step\n",
            "Epoch 5/10\n",
            "9569/9569 - 33s - loss: 0.0061 - 33s/epoch - 3ms/step\n",
            "Epoch 6/10\n",
            "9569/9569 - 34s - loss: 0.0059 - 34s/epoch - 4ms/step\n",
            "Epoch 7/10\n",
            "9569/9569 - 33s - loss: 0.0059 - 33s/epoch - 3ms/step\n",
            "Epoch 8/10\n",
            "9569/9569 - 34s - loss: 0.0058 - 34s/epoch - 4ms/step\n",
            "Epoch 9/10\n",
            "9569/9569 - 33s - loss: 0.0058 - 33s/epoch - 3ms/step\n",
            "Epoch 10/10\n",
            "9569/9569 - 33s - loss: 0.0058 - 33s/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Trabajo de Grado/Modelo LSTM/scaler_y30.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "import joblib\n",
        "\n",
        "url1 = '/content/drive/MyDrive/Reuniones/DatasetsWP2/Dataset1CodificadoV2.csv'\n",
        "data1 = pd.read_csv(url1)\n",
        "data1 = data1.drop('Unnamed: 0',axis=1)\n",
        "X = data1.drop(columns=['Inputs']).values\n",
        "y = data1['Inputs'].values\n",
        "\n",
        "\n",
        "# Escala los datos\n",
        "scaler_X = MinMaxScaler(feature_range=(0, 1))\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
        "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1))\n",
        "\n",
        "# Divide los datos\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.3, random_state=42)\n",
        "\n",
        "# Reestructura los datos para LSTM\n",
        "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "# Construye y entrena el modelo\n",
        "model = Sequential([\n",
        "    LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    LSTM(50),\n",
        "    Dense(1)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=2)\n",
        "\n",
        "# Guarda el modelo y los escaladores\n",
        "model.save('/content/drive/MyDrive/Trabajo de Grado/Modelo LSTM/lstmFunc30.h5')\n",
        "joblib.dump(scaler_X, '/content/drive/MyDrive/Trabajo de Grado/Modelo LSTM/scaler_X30.pkl')\n",
        "joblib.dump(scaler_y, '/content/drive/MyDrive/Trabajo de Grado/Modelo LSTM/scaler_y30.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "import joblib\n",
        "\n",
        "# Carga el modelo y los escaladores\n",
        "model = load_model('/content/drive/MyDrive/Trabajo de Grado/Modelo LSTM/lstmFunc30.h5')\n",
        "scaler_X = joblib.load('/content/drive/MyDrive/Trabajo de Grado/Modelo LSTM/scaler_X30.pkl')\n",
        "scaler_y = joblib.load('/content/drive/MyDrive/Trabajo de Grado/Modelo LSTM/scaler_y30.pkl')\n",
        "\n",
        "def make_prediction(new_data):\n",
        "    new_data_scaled = scaler_X.transform(new_data)\n",
        "    new_data_scaled = new_data_scaled.reshape((new_data_scaled.shape[0], 1, new_data_scaled.shape[1]))\n",
        "    prediction_scaled = model.predict(new_data_scaled)\n",
        "    prediction = scaler_y.inverse_transform(prediction_scaled)\n",
        "    return prediction\n",
        "\n",
        "# Lista de estaciones\n",
        "stations = [\n",
        "    \"Station_(02000)Cabecera Autopista Norte\",\n",
        "    \"Station_(02300)Calle 100\",\n",
        "    \"Station_(03000)Portal Suba\",\n",
        "    \"Station_(04000)Cabecera Calle 80\",\n",
        "    \"Station_(05000)Portal Américas\",\n",
        "    \"Station_(06000)Portal Eldorado\",\n",
        "    \"Station_(07000)Portal Sur\",\n",
        "    \"Station_(08000)Portal Tunal\",\n",
        "    \"Station_(09000)Cabecera Usme\",\n",
        "    \"Station_(10000)Portal 20 de Julio\"\n",
        "]\n",
        "\n",
        "# Mostrar las estaciones al usuario\n",
        "print(\"Selecciona una estación ingresando el número correspondiente:\")\n",
        "for i, station in enumerate(stations, 1):\n",
        "    print(f\"{i} {station}\")\n",
        "\n",
        "# Leer la selección del usuario\n",
        "station_index = int(input(\"Número de estación seleccionada: \")) - 1\n",
        "\n",
        "# Solicitar al usuario el resto de los valores\n",
        "print(\"Ingresa los valores para Month, Day, Day_Week_Number, Holidays, Hour, Minute, Outputs (en ese orden), separados por comas:\")\n",
        "input_str = input()  # El usuario ingresa los valores separados por comas\n",
        "values = [float(value) for value in input_str.split(',')]\n",
        "\n",
        "# Asegurar que se ingresaron 7 valores antes de proceder\n",
        "if len(values) != 7:\n",
        "    raise ValueError(\"Debes ingresar exactamente 7 valores.\")\n",
        "\n",
        "# Construir el array new_data\n",
        "new_data_values = values + [0.0] * 10  # Inicializa los valores de las estaciones con 0.0\n",
        "new_data_values[7 + station_index] = 1.0  # Establece la estación seleccionada a 1\n",
        "new_data = np.array([new_data_values])\n",
        "\n",
        "# Hacer la predicción\n",
        "prediction = make_prediction(new_data)\n",
        "print(\"La predicción para 'Inputs' es:\", prediction.flatten()[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVca0cQ-Mn_6",
        "outputId": "d3643547-5dff-4cbc-a47b-645fe4b110c2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecciona una estación ingresando el número correspondiente:\n",
            "1 Station_(02000)Cabecera Autopista Norte\n",
            "2 Station_(02300)Calle 100\n",
            "3 Station_(03000)Portal Suba\n",
            "4 Station_(04000)Cabecera Calle 80\n",
            "5 Station_(05000)Portal Américas\n",
            "6 Station_(06000)Portal Eldorado\n",
            "7 Station_(07000)Portal Sur\n",
            "8 Station_(08000)Portal Tunal\n",
            "9 Station_(09000)Cabecera Usme\n",
            "10 Station_(10000)Portal 20 de Julio\n",
            "Número de estación seleccionada: 3\n",
            "Ingresa los valores para Month, Day, Day_Week_Number, Holidays, Hour, Minute, Outputs (en ese orden), separados por comas:\n",
            "12, 4, 1, 0, 10, 15, 42\n",
            "1/1 [==============================] - 1s 725ms/step\n",
            "La predicción para 'Inputs' es: 7.4791074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LGJoQDdBMxmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo 80-20\n"
      ],
      "metadata": {
        "id": "pcfk1jMaQPmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "import joblib\n",
        "\n",
        "url1 = '/content/drive/MyDrive/Reuniones/DatasetsWP2/Dataset1CodificadoV2.csv'\n",
        "data1 = pd.read_csv(url1)\n",
        "data1 = data1.drop('Unnamed: 0',axis=1)\n",
        "X = data1.drop(columns=['Inputs']).values\n",
        "y = data1['Inputs'].values\n",
        "\n",
        "\n",
        "# Escala los datos\n",
        "scaler_X = MinMaxScaler(feature_range=(0, 1))\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
        "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1))\n",
        "\n",
        "# Divide los datos\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.3, random_state=42)\n",
        "\n",
        "# Reestructura los datos para LSTM\n",
        "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "# Construye y entrena el modelo\n",
        "model = Sequential([\n",
        "    LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    LSTM(50),\n",
        "    Dense(1)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=2)\n",
        "\n",
        "# Guarda el modelo y los escaladores\n",
        "model.save('/content/drive/MyDrive/Trabajo de Grado/Modelo LSTM/lstmFunc20.h5')\n",
        "joblib.dump(scaler_X, '/content/drive/MyDrive/Trabajo de Grado/Modelo LSTM/scaler_X20.pkl')\n",
        "joblib.dump(scaler_y, '/content/drive/MyDrive/Trabajo de Grado/Modelo LSTM/scaler_y20.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZzYh3WaQTfe",
        "outputId": "a71688b1-7286-44d9-ff8e-918003a06cc7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "9569/9569 - 39s - loss: 0.0089 - 39s/epoch - 4ms/step\n",
            "Epoch 2/10\n",
            "9569/9569 - 36s - loss: 0.0070 - 36s/epoch - 4ms/step\n",
            "Epoch 3/10\n",
            "9569/9569 - 37s - loss: 0.0063 - 37s/epoch - 4ms/step\n",
            "Epoch 4/10\n",
            "9569/9569 - 36s - loss: 0.0062 - 36s/epoch - 4ms/step\n",
            "Epoch 5/10\n",
            "9569/9569 - 35s - loss: 0.0060 - 35s/epoch - 4ms/step\n",
            "Epoch 6/10\n",
            "9569/9569 - 34s - loss: 0.0059 - 34s/epoch - 4ms/step\n",
            "Epoch 7/10\n",
            "9569/9569 - 35s - loss: 0.0059 - 35s/epoch - 4ms/step\n",
            "Epoch 8/10\n",
            "9569/9569 - 35s - loss: 0.0058 - 35s/epoch - 4ms/step\n",
            "Epoch 9/10\n",
            "9569/9569 - 36s - loss: 0.0058 - 36s/epoch - 4ms/step\n",
            "Epoch 10/10\n",
            "9569/9569 - 34s - loss: 0.0058 - 34s/epoch - 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Trabajo de Grado/Modelo LSTM/scaler_y20.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "import joblib\n",
        "\n",
        "# Carga el modelo y los escaladores\n",
        "model = load_model('/content/drive/MyDrive/Trabajo de Grado/Modelo LSTM/lstmFunc20.h5')\n",
        "scaler_X = joblib.load('/content/drive/MyDrive/Trabajo de Grado/Modelo LSTM/scaler_X20.pkl')\n",
        "scaler_y = joblib.load('/content/drive/MyDrive/Trabajo de Grado/Modelo LSTM/scaler_y20.pkl')\n",
        "\n",
        "def make_prediction(new_data):\n",
        "    new_data_scaled = scaler_X.transform(new_data)\n",
        "    new_data_scaled = new_data_scaled.reshape((new_data_scaled.shape[0], 1, new_data_scaled.shape[1]))\n",
        "    prediction_scaled = model.predict(new_data_scaled)\n",
        "    prediction = scaler_y.inverse_transform(prediction_scaled)\n",
        "    return prediction\n",
        "\n",
        "# Lista de estaciones\n",
        "stations = [\n",
        "    \"Station_(02000)Cabecera Autopista Norte\",\n",
        "    \"Station_(02300)Calle 100\",\n",
        "    \"Station_(03000)Portal Suba\",\n",
        "    \"Station_(04000)Cabecera Calle 80\",\n",
        "    \"Station_(05000)Portal Américas\",\n",
        "    \"Station_(06000)Portal Eldorado\",\n",
        "    \"Station_(07000)Portal Sur\",\n",
        "    \"Station_(08000)Portal Tunal\",\n",
        "    \"Station_(09000)Cabecera Usme\",\n",
        "    \"Station_(10000)Portal 20 de Julio\"\n",
        "]\n",
        "\n",
        "# Mostrar las estaciones al usuario\n",
        "print(\"Selecciona una estación ingresando el número correspondiente:\")\n",
        "for i, station in enumerate(stations, 1):\n",
        "    print(f\"{i} {station}\")\n",
        "\n",
        "# Leer la selección del usuario\n",
        "station_index = int(input(\"Número de estación seleccionada: \")) - 1\n",
        "\n",
        "# Solicitar al usuario el resto de los valores\n",
        "print(\"Ingresa los valores para Month, Day, Day_Week_Number, Holidays, Hour, Minute, Outputs (en ese orden), separados por comas:\")\n",
        "input_str = input()  # El usuario ingresa los valores separados por comas\n",
        "values = [float(value) for value in input_str.split(',')]\n",
        "\n",
        "# Asegurar que se ingresaron 7 valores antes de proceder\n",
        "if len(values) != 7:\n",
        "    raise ValueError(\"Debes ingresar exactamente 7 valores.\")\n",
        "\n",
        "# Construir el array new_data\n",
        "new_data_values = values + [0.0] * 10  # Inicializa los valores de las estaciones con 0.0\n",
        "new_data_values[7 + station_index] = 1.0  # Establece la estación seleccionada a 1\n",
        "new_data = np.array([new_data_values])\n",
        "\n",
        "# Hacer la predicción\n",
        "prediction = make_prediction(new_data)\n",
        "print(\"La predicción para 'Inputs' es:\", prediction.flatten()[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAGkU2tbQZpb",
        "outputId": "a610a725-0fcd-47e4-c101-ab404ed8e545"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecciona una estación ingresando el número correspondiente:\n",
            "1 Station_(02000)Cabecera Autopista Norte\n",
            "2 Station_(02300)Calle 100\n",
            "3 Station_(03000)Portal Suba\n",
            "4 Station_(04000)Cabecera Calle 80\n",
            "5 Station_(05000)Portal Américas\n",
            "6 Station_(06000)Portal Eldorado\n",
            "7 Station_(07000)Portal Sur\n",
            "8 Station_(08000)Portal Tunal\n",
            "9 Station_(09000)Cabecera Usme\n",
            "10 Station_(10000)Portal 20 de Julio\n",
            "Número de estación seleccionada: 3\n",
            "Ingresa los valores para Month, Day, Day_Week_Number, Holidays, Hour, Minute, Outputs (en ese orden), separados por comas:\n",
            "12, 4, 1, 0, 10, 15, 42\n",
            "1/1 [==============================] - 1s 753ms/step\n",
            "La predicción para 'Inputs' es: 2.888681\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SPZt9_4dR58Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}