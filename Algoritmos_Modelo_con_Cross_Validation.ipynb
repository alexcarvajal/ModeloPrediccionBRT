{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "kHvF_GN1U65e",
        "z25_I3fmYcSy",
        "aAXTAjREYmGC",
        "K2u4w2VPbCJR"
      ],
      "mount_file_id": "1YsNBuAPj8-0dlZoJldgRDzxbkYV8jjI3",
      "authorship_tag": "ABX9TyMpFyp+ViPrJYWjKBazk+n5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexcarvajal/ModeloPrediccionBRT/blob/main/Algoritmos_Modelo_con_Cross_Validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo Cross-Validation Dataset 1\n"
      ],
      "metadata": {
        "id": "1DoYrRgEUyI0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest Dataset 1\n",
        "70% Entrenamiento - 30% Prueba"
      ],
      "metadata": {
        "id": "kHvF_GN1U65e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YM_77zdDF9WK",
        "outputId": "0c6622fb-28aa-4c22-863a-7253d1ef0490"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE promedio: 494.61328158426204\n",
            "R2 promedio: 0.47128453114728963\n",
            "MAPE promedio: inf\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import make_scorer, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def mape(y_true, y_pred):\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "# Cargar el dataset\n",
        "dataset_path = '/content/drive/MyDrive/Reuniones/DatasetsWP2/Dataset1Codificado.csv'\n",
        "\n",
        "data = pd.read_csv(dataset_path)\n",
        "\n",
        "# Eliminar columna innecesaria\n",
        "data = data.drop(columns=['Unnamed: 0'])\n",
        "\n",
        "# Separar las características (X) de la variable objetivo (y)\n",
        "X = data.drop(columns=['Inputs'])\n",
        "y = data['Inputs']\n",
        "\n",
        "# Inicializar el modelo de Random Forest para regresión\n",
        "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Definir las métricas para la validación cruzada\n",
        "scoring = {'MSE': make_scorer(mean_squared_error, greater_is_better=False),\n",
        "           'R2': 'r2',\n",
        "           'MAPE': make_scorer(mape, greater_is_better=False)}\n",
        "\n",
        "# Aplicar la validación cruzada\n",
        "cv_results = cross_validate(rf_regressor, X, y, cv=5, scoring=scoring, n_jobs=-1, return_train_score=False)\n",
        "\n",
        "# Calcular y mostrar los resultados\n",
        "print(f\"MSE promedio: {-cv_results['test_MSE'].mean()}\")\n",
        "print(f\"R2 promedio: {cv_results['test_R2'].mean()}\")\n",
        "print(f\"MAPE promedio: {-cv_results['test_MAPE'].mean()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM  Dataset 1\n",
        "70% Entrenamiento - 30% Prueba"
      ],
      "metadata": {
        "id": "z25_I3fmYcSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
        "\n",
        "# Cargar datos\n",
        "dataset_path = '/content/drive/MyDrive/Reuniones/DatasetsWP2/Dataset1Codificado.csv'\n",
        "data = pd.read_csv(dataset_path)\n",
        "\n",
        "# Preprocesamiento\n",
        "features = data.drop(columns=['Inputs', 'Unnamed: 0'])\n",
        "target = data['Inputs']\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "features_scaled = scaler.fit_transform(features)\n",
        "\n",
        "# Convertir datos para LSTM\n",
        "X = np.reshape(features_scaled, (features_scaled.shape[0], 1, features_scaled.shape[1]))\n",
        "y = target.values\n",
        "\n",
        "# Definir el modelo LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Callback para detener el entrenamiento\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, mode='min')\n",
        "\n",
        "# TimeSeriesSplit para la validación cruzada\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "metrics_summary = {'mse': [], 'r2': [], 'mape': []}\n",
        "\n",
        "for train_index, test_index in tscv.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Entrenar el modelo\n",
        "    history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), callbacks=[early_stopping], batch_size=32, verbose=0)\n",
        "\n",
        "    # Predecir\n",
        "    predictions = model.predict(X_test, verbose=0)\n",
        "\n",
        "    # Calcular métricas\n",
        "    mse = mean_squared_error(y_test, predictions)\n",
        "    r2 = r2_score(y_test, predictions)\n",
        "    mape = mean_absolute_percentage_error(y_test, predictions)\n",
        "\n",
        "    # Guardar métricas\n",
        "    metrics_summary['mse'].append(mse)\n",
        "    metrics_summary['r2'].append(r2)\n",
        "    metrics_summary['mape'].append(mape)\n",
        "\n",
        "    print(f'MSE: {mse}, R2: {r2}, MAPE: {mape}')\n",
        "\n",
        "# Mostrar resumen de métricas\n",
        "print(\"Resumen de métricas:\")\n",
        "print(f\"MSE promedio: {np.mean(metrics_summary['mse'])}\")\n",
        "print(f\"R2 promedio: {np.mean(metrics_summary['r2'])}\")\n",
        "print(f\"MAPE promedio: {np.mean(metrics_summary['mape'])}\")\n"
      ],
      "metadata": {
        "id": "HdZUhLBZGUuy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48191aa0-f12d-4462-bf45-c3c8e390f37f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 804.8328793750047, R2: 0.2371014559611302, MAPE: 1.4333623512150598e+16\n",
            "MSE: 829.042551003372, R2: 0.32607887848176, MAPE: 1.2698506935784214e+16\n",
            "MSE: 431.8103049858526, R2: 0.32422941016821016, MAPE: 8248134151799015.0\n",
            "MSE: 599.4288847300128, R2: 0.4898016083519853, MAPE: 9820309876494968.0\n",
            "MSE: 395.18621544881967, R2: 0.4047869152732646, MAPE: 7844698712112757.0\n",
            "Resumen de métricas:\n",
            "MSE promedio: 612.0601671086124\n",
            "R2 promedio: 0.35639965364727005\n",
            "MAPE promedio: 1.0589054637668312e+16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM  Dataset 1\n",
        "70% Entrenamiento - 30% Prueba\n",
        "\n"
      ],
      "metadata": {
        "id": "aAXTAjREYmGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Cargar datos\n",
        "dataset_path = '/content/drive/MyDrive/Reuniones/DatasetsWP2/Dataset1Codificado.csv'\n",
        "data = pd.read_csv(dataset_path)\n",
        "\n",
        "\n",
        "# Preprocesamiento básico\n",
        "# Eliminar columna innecesaria y separar características de la variable objetivo\n",
        "X = data.drop(columns=['Inputs', 'Unnamed: 0'])\n",
        "y = data['Inputs']\n",
        "\n",
        "# Crear un pipeline que primero estandariza los datos y luego aplica SVM\n",
        "svm_pipeline = make_pipeline(StandardScaler(), SVC(kernel='linear', random_state=42))\n",
        "\n",
        "# Aplicar validación cruzada\n",
        "cv_scores = cross_val_score(svm_pipeline, X, y, cv=5, scoring='accuracy')\n",
        "\n",
        "# Mostrar los resultados de la validación cruzada\n",
        "print(f\"Accuracy promedio: {cv_scores.mean()}\")\n",
        "print(f\"Desviación estándar: {cv_scores.std()}\")\n"
      ],
      "metadata": {
        "id": "tULxh3TlJgAT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2054a51-4262-4ac8-afa7-820aac5284ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bmYlav2HY4NQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost Dataset 1\n"
      ],
      "metadata": {
        "id": "K2u4w2VPbCJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "import numpy as np\n",
        "# Cargar datos\n",
        "dataset_path = '/content/drive/MyDrive/Reuniones/DatasetsWP2/Dataset1Codificado.csv'\n",
        "data = pd.read_csv(dataset_path)\n",
        "\n",
        "# Preprocesamiento básico\n",
        "X = data.drop(['Inputs', 'Unnamed: 0'], axis=1)\n",
        "y = data['Inputs']\n",
        "\n",
        "# Convertir datos a DMatrix, formato optimizado de XGBoost\n",
        "dtrain = xgb.DMatrix(X, label=y)\n",
        "\n",
        "# Parámetros de XGBoost\n",
        "params = {\n",
        "    'objective': 'reg:squarederror',  # Cambiar por 'reg:logistic' para clasificación, si es necesario\n",
        "    'eval_metric': ['rmse', 'mae'],  # Métricas de evaluación\n",
        "    'max_depth': 6,\n",
        "    'eta': 0.3,\n",
        "    'seed': 42\n",
        "}\n",
        "\n",
        "# Validación cruzada con XGBoost\n",
        "cv_results = xgb.cv(dtrain=dtrain, params=params, nfold=5, num_boost_round=50,\n",
        "                    metrics=('rmse', 'mae'), as_pandas=True, seed=42)\n",
        "\n",
        "# Mostrar resultados finales\n",
        "print(cv_results.tail(1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTP4yETfbGlG",
        "outputId": "f42eee3e-4d59-4c17-8636-d463f5c1c3f5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    train-rmse-mean  train-rmse-std  train-mae-mean  train-mae-std  \\\n",
            "49        20.910789        0.035241        12.43962       0.019574   \n",
            "\n",
            "    test-rmse-mean  test-rmse-std  test-mae-mean  test-mae-std  \n",
            "49       21.068221       0.057262      12.529507      0.033216  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rQyeLmGjbqQq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}