{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "kHvF_GN1U65e",
        "z25_I3fmYcSy",
        "aAXTAjREYmGC",
        "K2u4w2VPbCJR",
        "3gFzmVLXjkq1",
        "lm3_v8Hqj3sN",
        "Fhkp61TpkEr_",
        "4u07U7-hkOLU"
      ],
      "mount_file_id": "1YsNBuAPj8-0dlZoJldgRDzxbkYV8jjI3",
      "authorship_tag": "ABX9TyPcmU8tanc+6XSmv5boeogD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexcarvajal/ModeloPrediccionBRT/blob/main/Algoritmos_Modelo_con_Cross_Validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo Cross-Validation Dataset 1\n"
      ],
      "metadata": {
        "id": "1DoYrRgEUyI0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest Dataset 1\n",
        "70% Entrenamiento - 30% Prueba"
      ],
      "metadata": {
        "id": "kHvF_GN1U65e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YM_77zdDF9WK",
        "outputId": "0c6622fb-28aa-4c22-863a-7253d1ef0490"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE promedio: 494.61328158426204\n",
            "R2 promedio: 0.47128453114728963\n",
            "MAPE promedio: inf\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import make_scorer, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def mape(y_true, y_pred):\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "# Cargar el dataset\n",
        "dataset_path = '/content/drive/MyDrive/Reuniones/DatasetsWP2/Dataset1Codificado.csv'\n",
        "\n",
        "data = pd.read_csv(dataset_path)\n",
        "\n",
        "# Eliminar columna innecesaria\n",
        "data = data.drop(columns=['Unnamed: 0'])\n",
        "\n",
        "# Separar las características (X) de la variable objetivo (y)\n",
        "X = data.drop(columns=['Inputs'])\n",
        "y = data['Inputs']\n",
        "\n",
        "# Inicializar el modelo de Random Forest para regresión\n",
        "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Definir las métricas para la validación cruzada\n",
        "scoring = {'MSE': make_scorer(mean_squared_error, greater_is_better=False),\n",
        "           'R2': 'r2',\n",
        "           'MAPE': make_scorer(mape, greater_is_better=False)}\n",
        "\n",
        "# Aplicar la validación cruzada\n",
        "cv_results = cross_validate(rf_regressor, X, y, cv=5, scoring=scoring, n_jobs=-1, return_train_score=False)\n",
        "\n",
        "# Calcular y mostrar los resultados\n",
        "print(f\"MSE promedio: {-cv_results['test_MSE'].mean()}\")\n",
        "print(f\"R2 promedio: {cv_results['test_R2'].mean()}\")\n",
        "print(f\"MAPE promedio: {-cv_results['test_MAPE'].mean()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM  Dataset 1\n",
        "70% Entrenamiento - 30% Prueba"
      ],
      "metadata": {
        "id": "z25_I3fmYcSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
        "\n",
        "# Cargar datos\n",
        "dataset_path = '/content/drive/MyDrive/Reuniones/DatasetsWP2/Dataset1Codificado.csv'\n",
        "data = pd.read_csv(dataset_path)\n",
        "\n",
        "# Preprocesamiento\n",
        "features = data.drop(columns=['Inputs', 'Unnamed: 0'])\n",
        "target = data['Inputs']\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "features_scaled = scaler.fit_transform(features)\n",
        "\n",
        "# Convertir datos para LSTM\n",
        "X = np.reshape(features_scaled, (features_scaled.shape[0], 1, features_scaled.shape[1]))\n",
        "y = target.values\n",
        "\n",
        "# Definir el modelo LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Callback para detener el entrenamiento\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, mode='min')\n",
        "\n",
        "# TimeSeriesSplit para la validación cruzada\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "metrics_summary = {'mse': [], 'r2': [], 'mape': []}\n",
        "\n",
        "for train_index, test_index in tscv.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Entrenar el modelo\n",
        "    history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), callbacks=[early_stopping], batch_size=32, verbose=0)\n",
        "\n",
        "    # Predecir\n",
        "    predictions = model.predict(X_test, verbose=0)\n",
        "\n",
        "    # Calcular métricas\n",
        "    mse = mean_squared_error(y_test, predictions)\n",
        "    r2 = r2_score(y_test, predictions)\n",
        "    mape = mean_absolute_percentage_error(y_test, predictions)\n",
        "\n",
        "    # Guardar métricas\n",
        "    metrics_summary['mse'].append(mse)\n",
        "    metrics_summary['r2'].append(r2)\n",
        "    metrics_summary['mape'].append(mape)\n",
        "\n",
        "    print(f'MSE: {mse}, R2: {r2}, MAPE: {mape}')\n",
        "\n",
        "# Mostrar resumen de métricas\n",
        "print(\"Resumen de métricas:\")\n",
        "print(f\"MSE promedio: {np.mean(metrics_summary['mse'])}\")\n",
        "print(f\"R2 promedio: {np.mean(metrics_summary['r2'])}\")\n",
        "print(f\"MAPE promedio: {np.mean(metrics_summary['mape'])}\")\n"
      ],
      "metadata": {
        "id": "HdZUhLBZGUuy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48191aa0-f12d-4462-bf45-c3c8e390f37f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 804.8328793750047, R2: 0.2371014559611302, MAPE: 1.4333623512150598e+16\n",
            "MSE: 829.042551003372, R2: 0.32607887848176, MAPE: 1.2698506935784214e+16\n",
            "MSE: 431.8103049858526, R2: 0.32422941016821016, MAPE: 8248134151799015.0\n",
            "MSE: 599.4288847300128, R2: 0.4898016083519853, MAPE: 9820309876494968.0\n",
            "MSE: 395.18621544881967, R2: 0.4047869152732646, MAPE: 7844698712112757.0\n",
            "Resumen de métricas:\n",
            "MSE promedio: 612.0601671086124\n",
            "R2 promedio: 0.35639965364727005\n",
            "MAPE promedio: 1.0589054637668312e+16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM  Dataset 1\n",
        "70% Entrenamiento - 30% Prueba\n",
        "\n"
      ],
      "metadata": {
        "id": "aAXTAjREYmGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Cargar datos\n",
        "dataset_path = '/content/drive/MyDrive/Reuniones/DatasetsWP2/Dataset1Codificado.csv'\n",
        "data = pd.read_csv(dataset_path)\n",
        "\n",
        "\n",
        "# Preprocesamiento básico\n",
        "# Eliminar columna innecesaria y separar características de la variable objetivo\n",
        "X = data.drop(columns=['Inputs', 'Unnamed: 0'])\n",
        "y = data['Inputs']\n",
        "\n",
        "# Crear un pipeline que primero estandariza los datos y luego aplica SVM\n",
        "svm_pipeline = make_pipeline(StandardScaler(), SVC(kernel='linear', random_state=42))\n",
        "\n",
        "# Aplicar validación cruzada\n",
        "cv_scores = cross_val_score(svm_pipeline, X, y, cv=5, scoring='accuracy')\n",
        "\n",
        "# Mostrar los resultados de la validación cruzada\n",
        "print(f\"Accuracy promedio: {cv_scores.mean()}\")\n",
        "print(f\"Desviación estándar: {cv_scores.std()}\")\n"
      ],
      "metadata": {
        "id": "tULxh3TlJgAT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2054a51-4262-4ac8-afa7-820aac5284ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bmYlav2HY4NQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost Dataset 1\n"
      ],
      "metadata": {
        "id": "K2u4w2VPbCJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "import numpy as np\n",
        "# Cargar datos\n",
        "dataset_path = '/content/drive/MyDrive/Reuniones/DatasetsWP2/Dataset1Codificado.csv'\n",
        "data = pd.read_csv(dataset_path)\n",
        "\n",
        "# Preprocesamiento básico\n",
        "X = data.drop(['Inputs', 'Unnamed: 0'], axis=1)\n",
        "y = data['Inputs']\n",
        "\n",
        "# Convertir datos a DMatrix, formato optimizado de XGBoost\n",
        "dtrain = xgb.DMatrix(X, label=y)\n",
        "\n",
        "# Parámetros de XGBoost\n",
        "params = {\n",
        "    'objective': 'reg:squarederror',  # Cambiar por 'reg:logistic' para clasificación, si es necesario\n",
        "    'eval_metric': ['rmse', 'mae'],  # Métricas de evaluación\n",
        "    'max_depth': 6,\n",
        "    'eta': 0.3,\n",
        "    'seed': 42\n",
        "}\n",
        "\n",
        "# Validación cruzada con XGBoost\n",
        "cv_results = xgb.cv(dtrain=dtrain, params=params, nfold=5, num_boost_round=50,\n",
        "                    metrics=('rmse', 'mae'), as_pandas=True, seed=42)\n",
        "\n",
        "# Mostrar resultados finales\n",
        "print(cv_results.tail(1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTP4yETfbGlG",
        "outputId": "f42eee3e-4d59-4c17-8636-d463f5c1c3f5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    train-rmse-mean  train-rmse-std  train-mae-mean  train-mae-std  \\\n",
            "49        20.910789        0.035241        12.43962       0.019574   \n",
            "\n",
            "    test-rmse-mean  test-rmse-std  test-mae-mean  test-mae-std  \n",
            "49       21.068221       0.057262      12.529507      0.033216  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rQyeLmGjbqQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest Dataset 2\n",
        "70% Entrenamiento - 30% Prueba"
      ],
      "metadata": {
        "id": "3gFzmVLXjkq1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c6622fb-28aa-4c22-863a-7253d1ef0490",
        "id": "3E9-BZmVjkq9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE promedio: 494.61328158426204\n",
            "R2 promedio: 0.47128453114728963\n",
            "MAPE promedio: inf\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import make_scorer, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def mape(y_true, y_pred):\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "# Cargar el dataset\n",
        "dataset_path = '/content/drive/MyDrive/Reuniones/DatasetsWP2/Dataset2Codificado.csv'\n",
        "\n",
        "data = pd.read_csv(dataset_path)\n",
        "\n",
        "# Eliminar columna innecesaria\n",
        "data = data.drop(columns=['Unnamed: 0'])\n",
        "\n",
        "# Separar las características (X) de la variable objetivo (y)\n",
        "X = data.drop(columns=['Inputs'])\n",
        "y = data['Inputs']\n",
        "\n",
        "# Inicializar el modelo de Random Forest para regresión\n",
        "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Definir las métricas para la validación cruzada\n",
        "scoring = {'MSE': make_scorer(mean_squared_error, greater_is_better=False),\n",
        "           'R2': 'r2',\n",
        "           'MAPE': make_scorer(mape, greater_is_better=False)}\n",
        "\n",
        "# Aplicar la validación cruzada\n",
        "cv_results = cross_validate(rf_regressor, X, y, cv=5, scoring=scoring, n_jobs=-1, return_train_score=False)\n",
        "\n",
        "# Calcular y mostrar los resultados\n",
        "print(f\"MSE promedio: {-cv_results['test_MSE'].mean()}\")\n",
        "print(f\"R2 promedio: {cv_results['test_R2'].mean()}\")\n",
        "print(f\"MAPE promedio: {-cv_results['test_MAPE'].mean()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM  Dataset 2\n",
        "70% Entrenamiento - 30% Prueba"
      ],
      "metadata": {
        "id": "lm3_v8Hqj3sN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
        "\n",
        "# Cargar datos\n",
        "dataset_path = '/content/drive/MyDrive/Reuniones/DatasetsWP2/Dataset2Codificado.csv'\n",
        "data = pd.read_csv(dataset_path)\n",
        "\n",
        "# Preprocesamiento\n",
        "features = data.drop(columns=['Inputs', 'Unnamed: 0'])\n",
        "target = data['Inputs']\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "features_scaled = scaler.fit_transform(features)\n",
        "\n",
        "# Convertir datos para LSTM\n",
        "X = np.reshape(features_scaled, (features_scaled.shape[0], 1, features_scaled.shape[1]))\n",
        "y = target.values\n",
        "\n",
        "# Definir el modelo LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Callback para detener el entrenamiento\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, mode='min')\n",
        "\n",
        "# TimeSeriesSplit para la validación cruzada\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "metrics_summary = {'mse': [], 'r2': [], 'mape': []}\n",
        "\n",
        "for train_index, test_index in tscv.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Entrenar el modelo\n",
        "    history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), callbacks=[early_stopping], batch_size=32, verbose=0)\n",
        "\n",
        "    # Predecir\n",
        "    predictions = model.predict(X_test, verbose=0)\n",
        "\n",
        "    # Calcular métricas\n",
        "    mse = mean_squared_error(y_test, predictions)\n",
        "    r2 = r2_score(y_test, predictions)\n",
        "    mape = mean_absolute_percentage_error(y_test, predictions)\n",
        "\n",
        "    # Guardar métricas\n",
        "    metrics_summary['mse'].append(mse)\n",
        "    metrics_summary['r2'].append(r2)\n",
        "    metrics_summary['mape'].append(mape)\n",
        "\n",
        "    print(f'MSE: {mse}, R2: {r2}, MAPE: {mape}')\n",
        "\n",
        "# Mostrar resumen de métricas\n",
        "print(\"Resumen de métricas:\")\n",
        "print(f\"MSE promedio: {np.mean(metrics_summary['mse'])}\")\n",
        "print(f\"R2 promedio: {np.mean(metrics_summary['r2'])}\")\n",
        "print(f\"MAPE promedio: {np.mean(metrics_summary['mape'])}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48191aa0-f12d-4462-bf45-c3c8e390f37f",
        "id": "UXGDEUWTj3sU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 804.8328793750047, R2: 0.2371014559611302, MAPE: 1.4333623512150598e+16\n",
            "MSE: 829.042551003372, R2: 0.32607887848176, MAPE: 1.2698506935784214e+16\n",
            "MSE: 431.8103049858526, R2: 0.32422941016821016, MAPE: 8248134151799015.0\n",
            "MSE: 599.4288847300128, R2: 0.4898016083519853, MAPE: 9820309876494968.0\n",
            "MSE: 395.18621544881967, R2: 0.4047869152732646, MAPE: 7844698712112757.0\n",
            "Resumen de métricas:\n",
            "MSE promedio: 612.0601671086124\n",
            "R2 promedio: 0.35639965364727005\n",
            "MAPE promedio: 1.0589054637668312e+16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM  Dataset 2\n",
        "70% Entrenamiento - 30% Prueba\n",
        "\n"
      ],
      "metadata": {
        "id": "Fhkp61TpkEr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Cargar datos\n",
        "dataset_path = '/content/drive/MyDrive/Reuniones/DatasetsWP2/Dataset2Codificado.csv'\n",
        "data = pd.read_csv(dataset_path)\n",
        "\n",
        "\n",
        "# Preprocesamiento básico\n",
        "# Eliminar columna innecesaria y separar características de la variable objetivo\n",
        "X = data.drop(columns=['Inputs', 'Unnamed: 0'])\n",
        "y = data['Inputs']\n",
        "\n",
        "# Crear un pipeline que primero estandariza los datos y luego aplica SVM\n",
        "svm_pipeline = make_pipeline(StandardScaler(), SVC(kernel='linear', random_state=42))\n",
        "\n",
        "# Aplicar validación cruzada\n",
        "cv_scores = cross_val_score(svm_pipeline, X, y, cv=5, scoring='accuracy')\n",
        "\n",
        "# Mostrar los resultados de la validación cruzada\n",
        "print(f\"Accuracy promedio: {cv_scores.mean()}\")\n",
        "print(f\"Desviación estándar: {cv_scores.std()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2054a51-4262-4ac8-afa7-820aac5284ab",
        "id": "ipcmJTHCkEsG"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ntZKv-j4kEsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost Dataset 2\n"
      ],
      "metadata": {
        "id": "4u07U7-hkOLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "import numpy as np\n",
        "# Cargar datos\n",
        "dataset_path = '/content/drive/MyDrive/Reuniones/DatasetsWP2/Dataset2Codificado.csv'\n",
        "data = pd.read_csv(dataset_path)\n",
        "\n",
        "# Preprocesamiento básico\n",
        "y = data['Inputs']\n",
        "\n",
        "# Convertir datos a DMatrix, formato optimizado de XGBoost\n",
        "dtrain = xgb.DMatrix(X, label=y)\n",
        "\n",
        "# Parámetros de XGBoost\n",
        "params = {\n",
        "    'objective': 'reg:squarederror',  # Cambiar por 'reg:logistic' para clasificación, si es necesario\n",
        "    'eval_metric': ['rmse', 'mae'],  # Métricas de evaluación\n",
        "    'max_depth': 6,\n",
        "    'eta': 0.3,\n",
        "    'seed': 42\n",
        "}\n",
        "\n",
        "# Validación cruzada con XGBoost\n",
        "cv_results = xgb.cv(dtrain=dtrain, params=params, nfold=5, num_boost_round=50,\n",
        "                    metrics=('rmse', 'mae'), as_pandas=True, seed=42)\n",
        "\n",
        "# Mostrar resultados finales\n",
        "print(cv_results.tail(1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 587
        },
        "outputId": "3dfbefa2-62a3-41e1-aa4f-07b40592aa1e",
        "id": "E4J5zsrCkOLV"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "XGBoostError",
          "evalue": "[21:41:45] /workspace/src/data/data.cc:501: Check failed: this->labels.Size() % this->num_row_ == 0 (332080 vs. 0) : Incorrect size for labels.\nStack trace:\n  [bt] (0) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x3588ca) [0x7da5cdc678ca]\n  [bt] (1) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x389af7) [0x7da5cdc98af7]\n  [bt] (2) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x38ab51) [0x7da5cdc99b51]\n  [bt] (3) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(XGDMatrixSetInfoFromInterface+0xb0) [0x7da5cda6d3a0]\n  [bt] (4) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7da635629e2e]\n  [bt] (5) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7da635626493]\n  [bt] (6) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0xa3e9) [0x7da63564f3e9]\n  [bt] (7) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x9a00) [0x7da63564ea00]\n  [bt] (8) /usr/bin/python3(_PyObject_MakeTpCall+0x25b) [0x58e9266a0a7b]\n\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-7ad4d2953883>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Convertir datos a DMatrix, formato optimizado de XGBoost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Parámetros de XGBoost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical, data_split_mode)\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m         self.set_info(\n\u001b[0m\u001b[1;32m    870\u001b[0m             \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m             \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mset_info\u001b[0;34m(self, label, weight, base_margin, group, qid, label_lower_bound, label_upper_bound, feature_names, feature_types, feature_weights)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mset_label\u001b[0;34m(self, label)\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdispatch_meta_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1070\u001b[0;31m         \u001b[0mdispatch_meta_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"label\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"float\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArrayLike\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/data.py\u001b[0m in \u001b[0;36mdispatch_meta_backend\u001b[0;34m(matrix, data, name, dtype)\u001b[0m\n\u001b[1;32m   1223\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_pandas_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m         \u001b[0m_meta_from_pandas_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1226\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_dlpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/data.py\u001b[0m in \u001b[0;36m_meta_from_pandas_series\u001b[0;34m(data, name, dtype, handle)\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m     \u001b[0m_meta_from_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/data.py\u001b[0m in \u001b[0;36m_meta_from_numpy\u001b[0;34m(data, field, dtype, handle)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Masked array is not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m     \u001b[0minterface_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_array_interface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m     \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGDMatrixSetInfoFromInterface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterface_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \"\"\"\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mXGBoostError\u001b[0m: [21:41:45] /workspace/src/data/data.cc:501: Check failed: this->labels.Size() % this->num_row_ == 0 (332080 vs. 0) : Incorrect size for labels.\nStack trace:\n  [bt] (0) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x3588ca) [0x7da5cdc678ca]\n  [bt] (1) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x389af7) [0x7da5cdc98af7]\n  [bt] (2) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x38ab51) [0x7da5cdc99b51]\n  [bt] (3) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(XGDMatrixSetInfoFromInterface+0xb0) [0x7da5cda6d3a0]\n  [bt] (4) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7da635629e2e]\n  [bt] (5) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7da635626493]\n  [bt] (6) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0xa3e9) [0x7da63564f3e9]\n  [bt] (7) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x9a00) [0x7da63564ea00]\n  [bt] (8) /usr/bin/python3(_PyObject_MakeTpCall+0x25b) [0x58e9266a0a7b]\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xsnWPm6VkOLV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}